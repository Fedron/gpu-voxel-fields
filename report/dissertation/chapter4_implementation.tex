\chapter{Implementation}
This chapter will focus on the implementation of various methods for generating a discrete distance field. It will start
with a basic brute-force approach before delving into optimizations and other algorithms. Each implementation will
include a short performance test for comparison between different implementations.

\section{Brute-force Approach}
A brute-force implementation for calculating the discrete distance field given a voxel grid is the most straight-forward
to implement but will suffer from performance; especially as world sizes get larger.

To compute the distance field for a voxel grid using a brute-force approach, we consider a voxel, \(V\) at
\((x, y, z)\). The algorithm starts iterating from the origin of the world \((0, 0, 0)\) and progresses incrementally
along each axis of the grid. For every voxel in the grid, the Manhattan distance is calculated to \(V\). This exhaustive
method, while producing an accurate distance field, must explore every other possible coordinate within the grid; this
can be seen in Algorithm~\ref{alg:brute_force}.

In the worst-case scenario, the algorithm must evaluate the distance for all \(N^3\), where \(N\) is the size of one
axis and the grid has uniform dimensions. This, the worst-case complexity is \(O(N^3)\). In the best-case, when the
voxel \(V\) is located near the origin a complexity of \(O(1)\) can be achieved, but this is highly unlikely.

\begin{algorithm}
    \caption{Brute Force Distance Field Calculation}
    \label{alg:brute_force}
    \begin{algorithmic}[1]
        \REQUIRE Voxel grid size \(N\), Voxel grid \(V\), Voxel location \((x, y, z)\)
        \ENSURE Distance field grid \(D\)
        \STATE Initialize \(D[i][j][k] \gets N\) for all \(i, j, k \in [0, N-1]\)
        \FOR{\(i = 0\) to \(N-1\)}
        \FOR{\(j = 0\) to \(N-1\)}
        \FOR{\(k = 0\) to \(N-1\)}
        \IF{\(V[i][j][k]\) is solid}
        \STATE \(d \gets |i - x| + |j - y| + |x - z|\) \COMMENT{Manhattan distance calculation, this will be common to
            all implementations.}
        \IF{\(d < D[i][j][k]\)}
        \STATE \(D[i][j][k] \gets d\) \COMMENT{Write only the shortest distance to the output.}
        \ENDIF
        \ENDIF
        \ENDFOR
        \ENDFOR
        \ENDFOR
        \STATE \textbf{Return:} \(D\)
    \end{algorithmic}
\end{algorithm}

\subsection{Performance Results}
At very small world sizes, the performance of the brute-force algorithm is sufficient; however the performance gets
exponentially worse the larger the world becomes. At a world size above \(256^3\), the amount of work required by each
warp on the GPU becomes too large resulting in the application crashing, as such the testing for this only went to a
world size of \(128^3\).

\begin{table}[h]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \vspace{0.5em}
    \begin{tabular}{l|*{5}{c}}
        \toprule
        \textbf{World Size} & \textbf{\(8^3\)} & \textbf{\(16^3\)} & \textbf{\(32^3\)} & \textbf{\(64^3\)} & \textbf{\(128^3\)} \\
        \midrule
        \textbf{Avg. FPS}   & 142.33702        & 142.335887        & 91.44403          & 2.30128           & 0.04184            \\
        \bottomrule
    \end{tabular}
    \caption{Frame rate of the brute-force algorithm at varying world sizes with a modification every 200ms.}
    \label{tab:brute_force_fps}
\end{table}

\begin{table}[h]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \vspace{0.5em}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l|*{5}{c}}
            \toprule
            \textbf{World Size}               & \textbf{\(8^3\)}         & \textbf{\(16^3\)}      & \textbf{\(32^3\)}    & \textbf{\(64^3\)}    & \textbf{\(128^3\)}     \\
            \midrule
            \textbf{Avg. Time (ms)}           & 0.13085426               & 0.72909933             & 8.415086             & 431.46756            & 25854.305              \\
            \textbf{Std. Deviation (ms)}      & 0.07906039               & 0.72129595             & 0.6034345            & 23.69193             & 43.82031               \\
            \textbf{Confidence Interval (ms)} & (0.12865908, 0.13304944) & (0.7251273, 0.7330714) & (8.400318, 8.429853) & (428.5129, R34.4222) & (25830.484, 25878.125) \\
            \bottomrule
        \end{tabular}
    }
    \caption{Distance field compute shader execution time using the brute-force algorithm.}
    \label{tab:brute_force}
\end{table}

The results in Table~\ref{tab:brute_force} highlight how a brute-force approach is unsuitable for large dynamic worlds.
A common optimization is chunking to split a large world into smaller ``chunks'' as described in~\ref{sec:chunking}.

\section{Splitting a World into Chunks} \label{sec:chunking}
Partitioning, or chunking, is a common approach to divide a large problem into smaller manageable problems. In the
context of voxels world, sparse voxel octrees (SVO) are an approach for dividing a large dense representation of a voxel
grid into a more sparse format with data only stored where it's needed; this makes it more efficient to process and
render~\cite{laine2010efficient,mileff2019simplified,van2015real}.

Given that a brute-force approach has acceptable performance at a world size of \(16^3\), as can be seen in Table
\ref{tab:brute_force}, we can divide the whole world into smaller \(16^3\) chunks. This will allow for updates in one
chunk to be localized, as such updates will not be required to update the whole world reducing the amount of iterations
required to update a distance field.

For a \(512^3\) sized world, we could divide it into \(32,768\) chunks each with a size of \(16^3\). A worst-case
complexity for this significantly larger world is now \(O(16^3)\) compared to the \(O(512^3)\) it would otherwise be
without a chunking approach.

Chunks, however, present a significant problem in distance field generation as they can introduce inaccuracies between
chunk borders. This can happen if we don't consider the voxels in an adjacent chunk when calculating distances, there
are three potential solutions to this problem:

\begin{enumerate}
    \item When iterating over a chunk, iterate over a size \(X + 2, Y + 2, Z + 2\) to introduce ``padding''. Checking
          neighbours that are in padding region will be treated as solid which will introduce a border in the distance field
          that would force rays to march into the beginning of the next chunk.
    \item Include the adjacent chunks as input to the distance field compute shader. Out-of-bounds accesses should
          result in checking neigbouring chunks; however, this expands the number of voxels needed to be checked and will
          still suffer from inaccuracies if the nearest solid voxel is not in a neighbouring chunk.
    \item Combining the first approach, with multiple passes. An initial distance field calculation is computed for each
          chunk independently. To ensure accurate distances at chunk boundaries, another pass through the world can be done
          that includes neighbour information. Multiple, more global, passes will ensure distances eventually converge on the
          correct distance value~\cite{gorobets2023approach,sinharoy1993finding,xu2015fast}.
\end{enumerate}

\subsection{Padding}
The chosen approach at this point, is to introduce padding to an individual chunk when calculating the distance field.
With this approach the worst-case complexity is slightly worse than without using chunking. Without chunks a \(16^3\)
world, has a complexity \(O(N^3)\), with chunks we require padding and so a chunk of the same size would have a
complexity of \(O((N + 2)^3)\).

To account for the ``padding'' around a chunk, out-of-bounds accesses will be treated as a solid voxel.

\begin{algorithm}[H]
    \caption{Get Voxel at \((x, y, z)\)}
    \label{alg:get_voxel}
    \begin{algorithmic}[1]
        \REQUIRE Voxel grid \(V\), position \(x, y, z\)
        \IF{\(x, y, z\) is within bounds of \(V\)}
        \RETURN \(V[x][y][z]\)
        \ELSE
        \RETURN Solid voxel
        \ENDIF
    \end{algorithmic}
\end{algorithm}

The algorithm for the distance field calculation remains largely unchanged except for now using Algorithm
\ref{alg:get_voxel} to access the voxel grid \(V\) instead of direct access. The updated algorithm is now implemented
as follows.

\begin{algorithm}[H]
    \caption{Brute force Distance Field Calculation (With chunks)}
    \begin{algorithmic}[1]
        \REQUIRE Voxel grid size \(N\), Voxel grid \(V\), Voxel location \((x, y, z)\)
        \ENSURE Distance field grid \(D\)
        \STATE Initialize \(D[i][j][k] \gets N\) for all \(i, j, k \in [0, N-1]\)
        \FOR{\(i = -1\) to \(N\)}
        \FOR{\(j = -1\) to \(N\)}
        \FOR{\(k = -1\) to \(N\)}
        \STATE \texttt{voxel} $\gets$ \texttt{Get Voxel at} \((i, j, k)\)
        \IF{\texttt{voxel is solid}}
        \STATE \(d \gets |i - x| + |j - y| + |x - z|\)
        \IF{\(d < D[i][j][k]\)}
        \STATE \(D[i][j][k] \gets d\)
        \ENDIF
        \ENDIF
        \ENDFOR
        \ENDFOR
        \ENDFOR
        \STATE \textbf{Return:} \(D\)
    \end{algorithmic}
\end{algorithm}

\subsection{Performance Results}
Based on the performance results of the brute-force approach, as can be seen in Table~\ref{tab:brute_force}, the
proceeding tests will use a chunk size of \(16^3\). The key improvement in using chunks is that the total world size is
theoretically only limited by the memory consumption. Sufficiently large updates spanning multiple chunks will be less
performant, but we can expect that a small localized update affecting only a couple of chunks will have only marginally
worse performance than the previous approach.

\begin{table}[h!]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \vspace{0.5em}
    \begin{tabular}{l|*{5}{c}}
        \toprule
        \textbf{World Size}          & \textbf{\(32^3\)} & \textbf{\(64^3\)} & \textbf{\(128^3\)} & \textbf{\(256^3\)} & \textbf{\(512^3\)} \\
        \midrule
        \textbf{Avg. FPS}            & 141.02969         & 140.32344         & 88.75602           & 22.13375           & 3.37203            \\
        \textbf{Avg. Execution Time} & 0.8090571         & 0.7992149         & 0.7797105          & 0.7632012          & 0.7504562          \\
        \textbf{\% Improvement}      & 54.2251\%         & 5997.63\%         & 212032\%           & Inf\%              & Inf\%              \\
        \bottomrule
    \end{tabular}
    \caption{Frame rate, and execution time, of the brute-force algorithm, when using a chunk size of \(16^3\), at
        varying world sizes with a modification to the world every 200ms. Percentage improvement is the improvement in
        frame rate compared to a comparably sized world without chunks, as demonstrated in Table~\ref{tab:brute_force_fps}.}
\end{table}

\FloatBarrier

\section{Fast Iterative Method}
The fast marching method (FMM)~\cite{sethian1999fast} is an approach used for solving a boundary value problem; in the
case of a voxel grid distance field our boundary problem is defined as identifying the distances for each air voxel to
the nearest voxel.

FMM computes distance fields by propagating distance information outward from known boundary regions; the boundary
region for a voxel grid is computed by setting all solid voxels to a distance of 0 and all air voxels to a sufficiently
large number, this can be seen in Figure~\ref{fig:fmm_init} and Algorithm~\ref{alg:fmm_init}.

On a GPU, each voxel can be processed in parallel by leveraging atomic minimums. When distance information is propagated
in a single iteration only the minimum value is saved to the distance field. A distance can at most propagate 1 voxel
away from the voxel being processed, this means that to achieve an accurate distance field FMM must be executed on the
distance field several times until shortest distances have calculated for all voxels, the effect of several iterations
can be seen in Figure~\ref{fig:fmm}.

The number of iterations required for convergence is proportional to the size of a chunk - a voxel that is \(N\) units
away from the chunk boundary, will require at least \(N\) units to receive the correct distance value. As such, given a
chunk of size \(C = 8\), the total number of voxels to process is \(N = 8^3\), the worst-case computation will be
\(O(8N)\).

Convergence can be handled on the CPU or on the GPU, the chosen approach was to implement a single iteration of the FMM
algorithm, as can be seen in~\ref{alg:fmm}, as a compute shader. The CPU will dispatch the compute shader until no
changes have been made to the distance field.

\begin{algorithm}[H]
    \caption{Fast Marching Method, Distance Field Initialization}
    \label{alg:fmm_init}
    \begin{algorithmic}[1]
        \REQUIRE Voxel grid size \(N\), Voxel grid \(V\), Voxel location \((x, y, z)\)
        \ENSURE Distance field grid \(D\)
        \STATE \texttt{voxel} $\gets$ \texttt{Get Voxel at} \((x, y, z)\)
        \IF{\texttt{voxel is solid}}
        \STATE \(D[x][y][z] \gets 0\)
        \ELSE
        \STATE \(D[x][y][z] \gets N * 2\)
        \ENDIF
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption{Fast Marching Method}
    \label{alg:fmm}
    \begin{algorithmic}[1]
        \REQUIRE Voxel grid size \(N\), Voxel grid \(V\), Voxel location \((x, y, z)\)
        \ENSURE Distance field grid \(D\)
        \STATE \texttt{voxel} $\gets$ \texttt{Get Voxel at} \((x, y, z)\)
        \IF{\texttt{voxel is solid}}
        \STATE \textbf{Return:} \(D\)
        \ENDIF

        \STATE Initialize $d_{min} \gets N * 2$
        \FOR{neighbours $n$ of voxel}
        \STATE \texttt{neighbour} $\gets$ \texttt{Get Voxel at} $n$
        \IF{\texttt{neighbour is solid}}
        \STATE $d_n \gets 0$
        \ELSE
        \STATE $d_n \gets$ distance value at $n$
        \ENDIF
        \STATE $d_n \gets d_n + 1$
        \STATE $d_{min} \gets \min(d_{min}, d_n)$
        \ENDFOR

        \IF{$d_{min} <$ current distance of $voxel$}
        \STATE Update $D$ at $(x, y, z)$ to $d_{min}$
        \STATE Mark distance field as changed
        \ENDIF
        \STATE \textbf{Return:} \(D\)
    \end{algorithmic}
\end{algorithm}


\subsection{Performance Results}
FMM is expected to be significantly more efficient than the brute-force approach, as such the optimal chunk size to use
needs to be determined first. We can see from Table~\ref{tab:fmm_chunks}, that we are able to compute the distance field
for a chunk much faster; however at $128^3$ sized chunks the variance in the number of iterations required for
convergence leads to inconsistent performance.

\begin{table}[h]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \vspace{0.5em}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l|*{5}{c}}
            \toprule
            \textbf{Chunk Size}                         & \textbf{\(8^3\)} & \textbf{\(16^3\)} & \textbf{\(32^3\)} & \textbf{\(64^3\)} & \textbf{\(128^3\)} \\
            \midrule
            \textbf{Total Avg. Time (ms)}               & 0.0408411        & 0.05089584        & 0.1566725         & 1.089782          & 17.556416          \\
            \textbf{Std. Deviation (ms)}                & 0.012230597      & 0.009375835       & 0.07214462        & 0.5198319         & 16.088636          \\
            \textbf{Average Iterations for Convergence} & 1.0313779        & 1.1514729         & 1.4801816         & 2.3467271         & 6.194286           \\
            \bottomrule
        \end{tabular}
    }
    \caption{Distance field compute shader execution time (as a total of all iterations required to achieve convergence)
        using the FMM algorithm.}
    \label{tab:fmm_chunks}
\end{table}

Single chunk performance is observed to be excellent; however, at world sizes larger than the chunk size the performance
degrades substantially, this can be observed in Figure~\ref{fig:fmm}. This is due to the way synchronization is handled
by the CPU to achieve distance field convergence; there is a substantial amount of time waiting for fences to be
signalled before the compute shader can be executed again. This could be mitigated by refactoring the compute shader
such that synchronization between iterations is handled by the GPU reducing the need for expensive memory transfers and
extensive waiting on the CPU. The Fast Marching Method is inherently sequential and so is not well suited to parallelism
on the GPU, as such effort will instead be spent on implementing the Fast Iterative Method as described in section.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{groupplot}[
                group style={
                        group size=1 by 2,
                        vertical sep=4cm,
                    },
                grid=major
            ]

            \nextgroupplot[
                title={Frame Performance},
                xlabel={World Size (voxels)}, ylabel={Average FPS},
                xtick={64,128,256,512,1024},
                xticklabel style={rotate=45},
                legend pos=outer north east
            ]
            \addplot[red, thick, mark=*] coordinates {
                    (64,95.30249) (128,75.96144) (256,34.19493) (512,3.57249)
                };
            \addlegendentry{$16^3$ Chunks}

            \addplot[green, thick, mark=*] coordinates {
                    (64,95.03077) (128,83.51576) (256,45.91034) (512,21.19063) (1024,3.228742)
                };
            \addlegendentry{$32^3$ Chunks}

            \addplot[blue, thick, mark=*] coordinates {
                    (64,68.15260) (128,46.48674) (256,23.07958) (512,14.77858) (1024,4.26064)
                };
            \addlegendentry{$64^3$ Chunks}

            \nextgroupplot[
                title={Distance Field Computation},
                xlabel={World Size (voxels)}, ylabel={Avg. Execution Time (ms)},
                xtick={64,128,256,512,1024},
                xticklabel style={rotate=45},
                legend pos=outer north east
            ]
            \addplot[red, thick, mark=*] coordinates {
                    (64,0.07576919) (128,0.103998095) (256,0.22743346) (512,0.4117954)
                };
            \addlegendentry{$16^3$ Chunks}

            \addplot[green, thick, mark=*] coordinates {
                    (64,0.19434363) (128,0.32839835) (256,0.5721531) (512,0.81162566) (1024,1.0872366)
                };
            \addlegendentry{$32^3$ Chunks}

            \addplot[blue, thick, mark=*] coordinates {
                    (64,1.245831) (128,1.941034) (256,5.226551) (512,7.010742) (1024,7.7111363)
                };
            \addlegendentry{$64^3$ Chunks}
        \end{groupplot}
    \end{tikzpicture}

    \caption{Comparison of the performance of the Fast Marching Method at different world and chunk sizes.}
    \label{fig:fmm}
\end{figure}

\section{Jump Flooding Algorithm}
\begin{itemize}
    \item Well-suited for GPU
    \item Only provides approximations
    \item Quick but not exact
    \item Not useful for close-up distance fields, i.e. where player is close. But could be useful for seeding, or
          initializing distance fields with an approximation hence speeding up the algorithm run on the distance field.
\end{itemize}

\subsection{Performance Results}

\begin{table}[h]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \vspace{0.5em}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l|*{5}{c}}
            \toprule
            \textbf{Chunk Size}           & \textbf{\(8^3\)} & \textbf{\(16^3\)} & \textbf{\(32^3\)} & \textbf{\(64^3\)} & \textbf{\(128^3\)} \\
            \midrule
            \textbf{Total Avg. Time (ms)} & 0.031079482      & 0.37563447        & 0.07390518        & 0.38933817        & 8.052377           \\
            \textbf{Std. Deviation (ms)}  & 0.0060166107     & 0.0011396826      & 0.014052732       & 0.1003621         & 3.9264889          \\
            \bottomrule
        \end{tabular}
    }
    \caption{Distance field compute shader execution time using the JFA algorithm.}
\end{table}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{groupplot}[
                group style={
                        group size=1 by 2,
                        vertical sep=4cm,
                    },
                grid=major
            ]

            \nextgroupplot[
                title={Frame Performance},
                xlabel={World Size (voxels)}, ylabel={Average FPS},
                xtick={64,128,256,512,1024},
                xticklabel style={rotate=45},
                legend pos=outer north east
            ]
            \addplot[red, thick, mark=*] coordinates {
                    (64,140.95991) (128,139.21750) (256,58.62559) (512,7.22179)
                };
            \addlegendentry{$16^3$ Chunks}

            \addplot[green, thick, mark=*] coordinates {
                    (64,140.72791) (128,132.19121) (256,97.06799) (512,48.7238) (1024,5.75885)
                };
            \addlegendentry{$32^3$ Chunks}

            \addplot[blue, thick, mark=*] coordinates {
                    (64,79.47583) (128,59.17962) (256,52.03550) (512,43.55900) (1024,28.47231)
                };
            \addlegendentry{$64^3$ Chunks}

            \nextgroupplot[
                title={Distance Field Computation},
                xlabel={World Size (voxels)}, ylabel={Avg. Execution Time (ms)},
                xtick={64,128,256,512,1024},
                xticklabel style={rotate=45},
                legend pos=outer north east
            ]
            \addplot[red, thick, mark=*] coordinates {
                    (64,0.029005498) (128,0.025463749) (256,0.037660573) (512,0.045116894)
                };
            \addlegendentry{$16^3$ Chunks}

            \addplot[green, thick, mark=*] coordinates {
                    (64,0.06540906) (128,0.06330304) (256,0.066737905) (512,0.079189345) (1024,0.113251306)
                };
            \addlegendentry{$32^3$ Chunks}

            \addplot[blue, thick, mark=*] coordinates {
                    (64,0.38292697) (128,0.367488) (256,0.3376916) (512,0.3192967) (1024,0.31650382)
                };
            \addlegendentry{$64^3$ Chunks}
        \end{groupplot}
    \end{tikzpicture}

    \caption{Comparison of the performance of the Jump Flooding Algorithm at different world and chunk sizes.}
\end{figure}

\section{Coarse JFA with FIM Refinement}

\begin{enumerate}
    \item Use JFA to initialize the distance field
    \item Then use FIM to converge the distance field to an exact result
    \item Decrease the average number of iterations required for convergence
    \item Slightly faster
    \item Given the demonstration application, you can selectively choose the algorithm depending on the distance of the
          update to the camera. Far away updates can use JFA to quickly update the distance field, at a distance artifacts
          shouldn't be noticeable, while updates near the player can use just FIM to propagate the update within the chunk.
          Both algorithms only need to be used when a chunk's distance field is first calculated.
\end{enumerate}

\subsection{Performance Results}
Divided depending on how this combination of algorithms is deployed.

\subsubsection{Complete Recalculation using both JFA and FIM}
When a chunk needs the distance field recalculated, JFA is run to initialize the distance field, and then FIM is run
afterward to produce an exact result.

\begin{table}[h]
    \centering
    \sisetup{
        table-format=3.3,
        round-mode=places,
        round-precision=3
    }
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l|*{5}{c}}
            \toprule
            \textbf{Chunk Size}                         & \textbf{\(8^3\)} & \textbf{\(16^3\)} & \textbf{\(32^3\)} & \textbf{\(64^3\)} & \textbf{\(128^3\)} \\
            \midrule
            \textbf{Total Avg. Time (ms)}               & 0.04326828       & 0.042948034       & 0.142226286       & 0.8856182         & 16.556087          \\
            \textbf{Std. Deviation (ms)}                & 0.014001529      & 0.0082087135      & 0.004889435       & 0.48032447        & 13.672007          \\
            \textbf{Average Iterations for Convergence} & 0.21335079       & 0.41733277        & 0.9516885         & 1.2535588         & 4.1610336          \\
            \bottomrule
        \end{tabular}
    }
    \caption{Distance field compute shader execution time using hybrid JFA and FIM approach. Compared against a pure
        FIM execution.}
\end{table}

\subsubsection{Selective Algorithm Execution}
Choose what type of algorithm to execute:

\begin{enumerate}
    \item Hybrid - only needed for first computation. Uses JFA for initialization, and FIM for convergence.
    \item Pure JFA - can be used to initialize, or update, far away chunks.
    \item Pure FIM - can be used to update chunks with the most visual impact i.e. nearby chunks.
\end{enumerate}
